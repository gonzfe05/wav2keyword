{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: preprocesses\n",
    "output-file: preprocesses.html\n",
    "description: Preprocess audio datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-xdhxuiuj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-xdhxuiuj\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit d90a36d192e2981a41122c30a765c63158dd0557\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.0.dev0) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.0.dev0) (3.8.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.8.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (766 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m766.5/766.5 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.0.dev0) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.0.dev0) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.0.dev0) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.8.1->transformers==4.22.0.dev0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.22.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.22.0.dev0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.22.0.dev0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.22.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.22.0.dev0) (3.3)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.22.0.dev0-py3-none-any.whl size=4730094 sha256=a6fdca27c5df1e5762ab68449646179d652168fc4bec7a4cc06babc5111efb5c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bs8sx32g/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, regex, transformers\n",
      "Successfully installed regex-2022.8.17 tokenizers-0.12.1 transformers-4.22.0.dev0\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# %%capture\n",
    "\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "\n",
    "from typing import List, Callable\n",
    "from nbdev.showdoc import *\n",
    "from IPython.display import display,SVG\n",
    "from transformers import AutoFeatureExtractor\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from wav2keyword.datasets import dataloader_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Preprocessor(object):\n",
    "\n",
    "    def __init__(self, model_checkpoint: str = \"facebook/wav2vec2-base\", max_duration: float = 1.0):\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.max_duration = max_duration\n",
    "        self.FEATURE_EXTRACTOR = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "\n",
    "    def _preprocess_function(self, examples: List[dict]):\n",
    "        \"\"\"Runs the feature_extractor for the given checkpoint with max_duration.\n",
    "\n",
    "        Args:\n",
    "            examples (_type_): Audio example\n",
    "\n",
    "        Returns:\n",
    "            _type_: preprocessed example\n",
    "        \"\"\"\n",
    "        audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "        inputs = self.FEATURE_EXTRACTOR(\n",
    "            audio_arrays, \n",
    "            sampling_rate=self.FEATURE_EXTRACTOR.sampling_rate, \n",
    "            max_length=int(self.FEATURE_EXTRACTOR.sampling_rate * self.max_duration), \n",
    "            truncation=True,\n",
    "        )\n",
    "        return inputs\n",
    "\n",
    "    def preprocess(self, dataset: DatasetDict):\n",
    "        return dataset.map(self._preprocess_function, remove_columns=[\"audio\", \"file\"], batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Preprocessor.preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can feed audio clips to our model, we need to preprocess them. This is done by ü§ó Transformers `FeatureExtractor` which will normalize the inputs and put them in a format the model expects, as well as generate the other inputs that the model requires.\n",
    "\n",
    "We wrote a function that will preprocess our samples. The `_preprocess_function` is an internal function that will instantiate our feature extractor with the `AutoFeatureExtractor.from_pretrained` method, which will ensure that we get a preprocessor that corresponds to the model architecture we want to use.  \n",
    "The argument `truncation=True` and the maximum sample length we will ensure that very long inputs like the ones in the `_silence_` class can be safely batched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset superb (/home/jovyan/.cache/huggingface/datasets/superb/ks/1.9.0/ce836692657f82230c16b3bbcb93eaacdbfd7de4def3be90016f112d68683481)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c738ae5ae328407eb0b5d9b5cc407d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:362: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#|filter_stream Reusing\n",
    "#|filter_stream UserWarning\n",
    "#| eval: false\n",
    "\n",
    "data = dataloader_pipeline({'path': \"superb\", 'name': \"ks\"})\n",
    "dataset = data['dataset']\n",
    "sample = dataset['train'][:5]\n",
    "preprocessor = Preprocessor()\n",
    "preprocessed_sample = preprocessor._preprocess_function(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw sample durations in seconds: [95.183125, 61.8056875, 61.253875, 60.0, 61.1555]\n",
      "preprocessed sample durations in seconds: [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "sr = sample['audio'][0]['sampling_rate']\n",
    "print(f\"Raw sample durations in seconds: {[a['array'].shape[0]/sr for a in sample['audio']]}\")\n",
    "print(f\"preprocessed sample durations in seconds: {[a.shape[0]/sr for a in preprocessed_sample['input_values']]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply this function on all utterances in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command.\n",
    "\n",
    "This whole process is mapped in the `preprocess` function. The results are automatically cached by the ü§ó Datasets library to avoid spending time on this step the next time you run your notebook. The ü§ó Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). ü§ó Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5920d02c8d4f6986579c29fe8b96ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644e6a1456664847bfe7cbe72fd45af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c95536eaf08493cbec421f860d8c601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_values', 'label'],\n",
       "        num_rows: 51094\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_values', 'label'],\n",
       "        num_rows: 6798\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_values', 'label'],\n",
       "        num_rows: 3081\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| filter_stream UserWarning|VisibleDeprecationWarning|Parameter|gradient_checkpointing|warnings.warn|tensor\n",
    "#| eval: false\n",
    "\n",
    "preprocess_dataset = preprocessor.preprocess(dataset)\n",
    "preprocess_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
