# AUTOGENERATED! DO NOT EDIT! File to edit: ../08_xvector_embeddings.ipynb.

# %% auto 0
__all__ = ['AudioArray', 'XvectorModel']

# %% ../08_xvector_embeddings.ipynb 3
from transformers import Wav2Vec2ForXVector
from .audio_processor import AudioProcessor
from pydantic import BaseModel
import numpy as np
from glob import glob
from pathlib import Path
from random import choices
import torch

class AudioArray(BaseModel):
    array: np.ndarray
    class Config:
        arbitrary_types_allowed = True

class XvectorModel(object):

    def __init__(self, model_checkpoint: str, annoy_index_path: str = None) -> None:
        self.model_checkpoint = model_checkpoint
        self.model = Wav2Vec2ForXVector.from_pretrained(self.model_checkpoint)
        self.audio_processor = AudioProcessor(self.model_checkpoint)
        self.embeddings_dimention = 512
        self.annoy_handler = AnnoyHandler(self.embeddings_dimention, annoy_index_path)
    
    def prepare_raw_audio(self, raw_data: bytes, sample_width: int, channels: int, frame_rate: int):
        return self.audio_processor.encode_raw_audio(raw_data, sample_width, channels, frame_rate)
    
    def get_embeddings(self, inputs):
        with torch.no_grad():
            result = self.model(**inputs).embeddings
        return result

    def get_predicted_labels(self, logits):
        proj = self.model.objective._parameters['weight'].cpu().detach().numpy()
        return np.argmax(np.dot(logits, proj), axis=1)

