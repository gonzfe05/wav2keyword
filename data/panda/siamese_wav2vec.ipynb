{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# !pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "# -\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:01<00:00, 50336.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 == 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from random import choices, seed\n",
    "seed(1991)\n",
    "N = 100000\n",
    "\n",
    "class TableDistanceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, embeddings_files, labels):\n",
    "        self.X1 = []\n",
    "        self.X2 = []\n",
    "        self.dist = []\n",
    "        files = {}\n",
    "        for e in embeddings_files:\n",
    "            word = e.split('/')[-2]\n",
    "            files[word] = files.get(word, []) + [e]\n",
    "        n_w = len(files.keys())\n",
    "        for _ in tqdm(range(N)):\n",
    "            c = choices(list(files.keys()), k=1)[0]\n",
    "            chosen_file_x1 = choices(files[c], k=1)[0]\n",
    "            weights = [0.5/(n_w-1) if k != c else 0.5 for k in files.keys()]\n",
    "            chosen_word = choices(list(files.keys()), k=1, weights=weights)[0]\n",
    "            chosen_file_x2 = choices(files[chosen_word], k=1)[0]\n",
    "            self.X1.append(chosen_file_x1)\n",
    "            self.X2.append(chosen_file_x2)\n",
    "            self.dist.append(0 if c == chosen_word else 1)\n",
    "        self.dist = torch.Tensor(self.dist)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x1 = torch.load(self.X1[index])\n",
    "        x2 = torch.load(self.X2[index])\n",
    "        return F.pad(x1, (0, 0, 0, 49-x1.shape[0]), 'constant', 0)[None, :, :], F.pad(x2, (0, 0, 0, 49-x2.shape[0]), 'constant', 0)[None, :, :], self.dist[index]\n",
    "\n",
    "embeddings_files = choices(glob('embeddings_base/*/*.pt'), k=800)\n",
    "labels = [e.split('/')[-2] for e in embeddings_files]\n",
    "tableDistanceDataset = TableDistanceDataset(embeddings_files, labels)\n",
    "print(f\"{N} == {len(tableDistanceDataset)}\")\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_base/beef/beef_0_1655590825-SIP-A90CCE12F2CF-00003f00-chunk3.pt\n",
      "embeddings_base/drink/drink_0_1655668162-SIP-A90CCE12F2CF-00004093-chunk7.pt\n",
      "tensor(1.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "ixs = [ix for ix, f in enumerate(tableDistanceDataset.X1) if re.findall('beef_0_1655590825-SIP-A90CCE12F2CF-00003f00-chunk3', f)]\n",
    "for i in ixs:\n",
    "    if 'drink' in tableDistanceDataset.X2[i]:\n",
    "        print(tableDistanceDataset.X1[i])\n",
    "        print(tableDistanceDataset.X2[i])\n",
    "        print(tableDistanceDataset.dist[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_vocab_words: 84 , out_vocab_words: 69\n",
      "10 in vocab with most audios per word [('chicken', 91), ('orange', 63), ('can', 63), ('rice', 56), ('mein', 45), ('chow', 37), ('plate', 37), ('beef', 25), ('two', 22), ('bowl', 20)]\n",
      "10 out vocab with most audios per word [('bowls', 22), ('sprite', 22), ('brown', 17), ('noodles', 16), ('fry', 15), ('rangoons', 13), ('iced', 9), ('juice', 8), ('come', 7), ('vegetables', 6)]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "in_vocab_words = [f.split('/')[-2] for f in embeddings_files]\n",
    "out_vocab_words = [f.split('/')[-2] for f in glob('embeddings_base/*/*.pt') if f.split('/')[-2] not in in_vocab_words]\n",
    "print(f\"in_vocab_words: {len(set(in_vocab_words))} , out_vocab_words: {len(set(out_vocab_words))}\")\n",
    "print(f\"10 in vocab with most audios per word {Counter(in_vocab_words).most_common(10)}\")\n",
    "print(f\"10 out vocab with most audios per word {Counter(out_vocab_words).most_common(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "class Table2Representation(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nhid = 32\n",
    "\n",
    "        # build model\n",
    "        self.__build_model()\n",
    "    \n",
    "    def __build_model(self):\n",
    "        self.fc1 = nn.Conv2d(1, 20, 20, stride=2)\n",
    "        self.do1 = nn.Dropout(0.2)\n",
    "        self.out = nn.Conv2d(20, 1, 14, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.do1(x)\n",
    "        x = self.out(x)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Based upon https://github.com/PyTorchLightning/Siamese-Neural-Networks/blob/master/model.py\n",
    "class TableDistanceModule(pl.LightningModule):\n",
    "    def __init__(self, tableDistanceDataset):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tableDistanceDataset = tableDistanceDataset\n",
    "        self.datatrain, self.dataval, self.datatest = \\\n",
    "        torch.utils.data.random_split(self.tableDistanceDataset,\n",
    "                                      [round(N*0.8),\n",
    "                                       round(N*0.1),\n",
    "                                       round(N*0.1)])\n",
    "\n",
    "        self.table2Representation = Table2Representation()\n",
    "\n",
    "        # build model\n",
    "        self.__build_model()\n",
    "    \n",
    "    def __build_model(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.table2Representation.forward(x1)\n",
    "        z2 = self.table2Representation.forward(x2)\n",
    "        dis = torch.mean(torch.abs(z1 - z2), axis=1)\n",
    "        return dis\n",
    "\n",
    "    def loss(self, pred_dists, true_dists):\n",
    "        loss_val = F.mse_loss(pred_dists, true_dists)\n",
    "        return loss_val\n",
    "    \n",
    "    def _step(self, batch, batch_idx, name, training_step=False):\n",
    "        X1, X2, dist = batch\n",
    "        pred = self.forward(X1, X2)\n",
    "        loss_val = self.loss(pred, dist)\n",
    "        tqdm_dict = OrderedDict({name: loss_val})\n",
    "        self.log_dict(tqdm_dict)\n",
    "        if training_step:\n",
    "            return OrderedDict({\n",
    "                'loss': loss_val,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "        else:\n",
    "            return tqdm_dict\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, name=\"train_loss\", training_step=True)\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, name=\"val_loss\", training_step=False)\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, name=\"test_loss\", training_step=False)\n",
    "\n",
    "    def _epoch_end(self, outputs, name):\n",
    "        # With DP training I think you have to average the things individually? Not sure\n",
    "        # Look at the pytorch lightning siamese network code\n",
    "        #if self.trainer.use_dp or self.trainer.use_ddp2:\n",
    "        #    val_acc = torch.mean(val_acc)\n",
    "        avg_loss = torch.stack([x[name] for x in outputs]).mean()\n",
    "        tqdm_dict = {name: avg_loss}\n",
    "        self.log_dict(tqdm_dict)\n",
    "        result = OrderedDict({name: avg_loss, 'progress_bar': tqdm_dict, 'log': tqdm_dict})\n",
    "        return result\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        result = self._epoch_end(outputs, name=\"val_loss\")\n",
    "        self.log_dict(result)\n",
    "        return result\n",
    "    def test_epoch_end(self, outputs):\n",
    "        result = self._epoch_end(outputs, name=\"test_loss\")\n",
    "        self.log_dict(result)\n",
    "        return result\n",
    "        \n",
    "    # ---------------------\n",
    "    # TRAINING SETUP\n",
    "    # ---------------------\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        return whatever optimizers we want here\n",
    "        :return: list of optimizers\n",
    "        \"\"\"\n",
    "        optimizer = optim.SGD(self.parameters(),\n",
    "                             lr=0.01, momentum=0.90)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                         T_max=10)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def __dataloader(self, train, dataset):\n",
    "        # when using multi-node (ddp) we need to add the  datasampler\n",
    "        train_sampler = None\n",
    "        batch_size = BATCH_SIZE\n",
    "\n",
    "        should_shuffle = train and train_sampler is None\n",
    "        loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=should_shuffle,\n",
    "            sampler=train_sampler,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        logging.info('training data loader called')\n",
    "        return self.__dataloader(train=True, dataset=self.datatrain)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        logging.info('val data loader called')\n",
    "        return self.__dataloader(train=False, dataset=self.dataval)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        logging.info('val data loader called')\n",
    "        return self.__dataloader(train=False, dataset=self.datatest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /workspaces/wav2keyword/data/panda/lightning_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                 | Type                 | Params\n",
      "--------------------------------------------------------------\n",
      "0 | table2Representation | Table2Representation | 11.9 K\n",
      "--------------------------------------------------------------\n",
      "11.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.9 K    Total params\n",
      "0.048     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2a0152d5a944db9c7ebf7c3506cc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:225: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:225: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd85ff5ab024ad6b12b2a2311a5c28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5848c493c5246d0b344b037ff7c6217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:288: UserWarning: The ``compute`` method of metric _ResultMetric was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd1f4284ad042cb8647b977f4253240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d604a4149afd492bb5db05ecc1123afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacb6956782e41e9a85e05b407062566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b6cca586bc46eea880419c79c95faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff07b454064412dad3adfab6021e6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c480f8c6b93475193e0c8e0ca633b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42493f15096546e89b2b074b1eab744b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd1a0bd4e6f4042b13c54ee010a2830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b5bb469db14af694729e612837e294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9228a9046d4623bd896b2193f59e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b018682b137424da758e80e097fa504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9926f02ed864a00a2f1dfa4ca50e02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611fe58496d442598e4ad861d9b96c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab08cf5b28c463d98a97e1ee5d73367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "model_gpu = TableDistanceModule(tableDistanceDataset)\n",
    "trainer_gpu = Trainer(max_epochs=15, gpus=-1)\n",
    "for i, (x, y, d) in enumerate(model_gpu.datatrain):\n",
    "    print(x.device)\n",
    "    print(y.device)\n",
    "    print(d.device)\n",
    "    break\n",
    "for p in model_gpu.parameters():\n",
    "    print(p.device)\n",
    "trainer_gpu.fit(model_gpu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1386: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /workspaces/wav2keyword/data/panda/lightning_logs/version_0/checkpoints/epoch=14-step=37500.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /workspaces/wav2keyword/data/panda/lightning_logs/version_0/checkpoints/epoch=14-step=37500.ckpt\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:225: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a154dd1d6c6c435b971afc5395248857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      log:test_loss         0.14371803402900696\n",
      " progress_bar:test_loss     0.14371803402900696\n",
      "        test_loss           0.14371803402900696\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.14371803402900696,\n",
       "  'progress_bar': {'test_loss': tensor(0.1437, device='cuda:0')},\n",
       "  'log': {'test_loss': tensor(0.1437, device='cuda:0')}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "trainer_gpu.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:24<00:00, 408.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4999.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "pos_ratio_test = []\n",
    "\n",
    "for i, (x, y, d) in tqdm(enumerate(model_gpu.datatest), total=len(model_gpu.datatest)):\n",
    "    pos_ratio_test.append(d.item())\n",
    "\n",
    "sum(pos_ratio_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "sum(pos_ratio_test)/len(pos_ratio_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "model = TableDistanceModule.load_from_checkpoint('lightning_logs/version_0/checkpoints/epoch=14-step=37500.ckpt', tableDistanceDataset=tableDistanceDataset)\n",
    "model_gpu = TableDistanceModule(tableDistanceDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------0----------\n",
      "positive diff: 0.31\n",
      "positive acc: 0.78\n",
      "Negative diff: 0.45\n",
      "negative acc: 0.64\n",
      "Overall diff: 0.37\n",
      "------10----------\n",
      "positive diff: 0.29\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.34\n",
      "negative acc: 0.75\n",
      "Overall diff: 0.31\n",
      "------20----------\n",
      "positive diff: 0.28\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.77\n",
      "Overall diff: 0.3\n",
      "------30----------\n",
      "positive diff: 0.28\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.32\n",
      "negative acc: 0.77\n",
      "Overall diff: 0.3\n",
      "------40----------\n",
      "positive diff: 0.28\n",
      "positive acc: 0.83\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.77\n",
      "Overall diff: 0.3\n",
      "------50----------\n",
      "positive diff: 0.28\n",
      "positive acc: 0.84\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------60----------\n",
      "positive diff: 0.28\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------70----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------80----------\n",
      "positive diff: 0.28\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------90----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------100----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.32\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.3\n",
      "------110----------\n",
      "positive diff: 0.28\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.32\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.3\n",
      "------120----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.32\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------130----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.32\n",
      "negative acc: 0.75\n",
      "Overall diff: 0.3\n",
      "------140----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------150----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------160----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------170----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------180----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------190----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------200----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------210----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------220----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------230----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------240----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------250----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------260----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------270----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------280----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------290----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------300----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.85\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n",
      "------310----------\n",
      "positive diff: 0.27\n",
      "positive acc: 0.86\n",
      "Negative diff: 0.31\n",
      "negative acc: 0.76\n",
      "Overall diff: 0.29\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "import time \n",
    "\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "# predict with the model\n",
    "pos_diff = []\n",
    "neg_diff = []\n",
    "pos_acc = []\n",
    "neg_acc = []\n",
    "for ix, (x, y, d) in enumerate(iter(model_gpu.test_dataloader())):\n",
    "    non_trivial = [ix for ix, (a, b) in enumerate(zip(x, y)) if ~torch.equal(a, b)]\n",
    "    x = x[non_trivial]\n",
    "    y = y[non_trivial]\n",
    "    d_hat = model(x, y)\n",
    "    indices = torch.nonzero(d)\n",
    "    nonzero_diff = torch.sum(torch.abs(d_hat[indices] - d[indices]), dim=0).item()\n",
    "    zero_diff = torch.sum(torch.abs(d_hat[d == 0] - d[d == 0]), dim=0).item()\n",
    "    pos_acc.append((sum([(0 if i.item() < 0.6 else 1) == t for i, t in zip(d_hat[indices], d[indices])]).item(),\n",
    "                    len(d[indices])))\n",
    "    neg_acc.append((sum([(0 if i.item() < 0.6 else 1) == t for i, t in zip(d_hat[d == 0], d[d == 0])]).item(),\n",
    "                    len(d[d == 0])))\n",
    "    pos_diff.append((nonzero_diff, len(d[indices])))\n",
    "    neg_diff.append((zero_diff, len(d[d == 0])))\n",
    "    if ix % 10 == 0:\n",
    "        print(f\"------{ix}----------\")\n",
    "        print(f\"positive diff: {round(sum([s for s, _ in pos_diff]) / sum([n for _, n in pos_diff]), 2)}\")\n",
    "        print(f\"positive acc: {round(sum([s for s, _ in pos_acc])/sum([l for _, l in pos_acc]), 2)}\")\n",
    "        print(f\"Negative diff: {round(sum([s for s, _ in neg_diff]) / sum([n for _, n in neg_diff]), 2)}\")\n",
    "        print(f\"negative acc: {round(sum([s for s, _ in neg_acc])/sum([l for _, l in neg_acc]), 2)}\")\n",
    "        print(f\"Overall diff: {round(sum([s1 + s2 for (s1, _), (s2, _) in zip(pos_diff, neg_diff)]) / sum([n1+n2 for (_, n1), (_, n2) in zip(pos_diff, neg_diff)]), 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "test_indices = model_gpu.datatest.indices\n",
    "x1 = [x for ix, x in enumerate(model_gpu.datatest.dataset.X1) if ix in test_indices]\n",
    "x2 = [x for ix, x in enumerate(model_gpu.datatest.dataset.X2) if ix in test_indices]\n",
    "dists = [x for ix, x in enumerate(model_gpu.datatest.dataset.dist) if ix in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [03:30<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "from pathlib import Path\n",
    "    \n",
    "import shutil\n",
    "pos_hits = 0\n",
    "pos_errs = 0\n",
    "pos_n = 0\n",
    "neg_hits = 0\n",
    "neg_errs = 0\n",
    "neg_n = 0\n",
    "\n",
    "for ix, i in tqdm(enumerate(range(32, len(x1), 32)), total=int(len(x1)/32)):\n",
    "    x, y, label = x1[i-32:i], x2[i-32:i], dists[i-32:i]\n",
    "    ex = [torch.load(e) for e in x]\n",
    "    ey = [torch.load(e) for e in y]\n",
    "    ex= [F.pad(e[None], (0, 0, 0, 49-e.shape[0]), 'constant', 0) for e in ex]\n",
    "    ey= [F.pad(e[None], (0, 0, 0, 49-e.shape[0]), 'constant', 0) for e in ey]\n",
    "    ex = torch.stack(ex)\n",
    "    ey = torch.stack(ey)\n",
    "    pred = model(ex, ey)\n",
    "    for jx, (t, d, xf, yf) in enumerate(zip(label, pred, x, y)):\n",
    "        d = 0 if d < 0.6 else 1\n",
    "        neg_n += 1 if t == 0 else 0\n",
    "        neg_hits += 1 if (t == 0) and (d == 0) else 0\n",
    "        neg_errs += 1 if (t == 0) and (d == 1) else 0\n",
    "        pos_n += 1 if t == 1 else 0\n",
    "        pos_hits += 1 if (t == 1) and (d == 1) else 0\n",
    "        pos_errs += 1 if (t == 1) and (d == 0) else 0\n",
    "\n",
    "        if xf == yf:\n",
    "            continue\n",
    "        xn = Path(xf).name\n",
    "        yn = Path(yf).name\n",
    "        xtrans = xn.split('_')[0]\n",
    "        ytrans = yn.split('_')[0]\n",
    "        if (xtrans != ytrans) and (t == 0):\n",
    "            print(xn, yn, xtrans, ytrans, t, d)\n",
    "            break\n",
    "        if (xtrans == ytrans) and (t == 1):\n",
    "            print(xn, yn, xtrans, ytrans, t, d)\n",
    "            break\n",
    "        if d == 0 and t == 0:\n",
    "            Path(f\"results/emb_sim/correct_same/{xtrans}\").mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(f\"{Path.home()}/.cache/panda/audio_slices/{yn.replace('.pt', '.wav')}\", f\"results/emb_sim/correct_same/{xtrans}/{ix}_{jx}_{yn.replace('.pt', '.wav')}\")\n",
    "        if d == 1 and t == 0:\n",
    "            Path(f\"results/emb_sim/incorrect_dif/{xtrans}\").mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(f\"{Path.home()}/.cache/panda/audio_slices/{yn.replace('.pt', '.wav')}\", f\"results/emb_sim/incorrect_dif/{xtrans}/{ix}_{jx}_{yn.replace('.pt', '.wav')}\")\n",
    "        if d == 0 and t == 1:\n",
    "            Path(f\"results/emb_sim/incorrect_same/{xtrans}\").mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(f\"{Path.home()}/.cache/panda/audio_slices/{yn.replace('.pt', '.wav')}\", f\"results/emb_sim/incorrect_same/{xtrans}/{ix}_{jx}_{yn.replace('.pt', '.wav')}\")\n",
    "        if d == 1 and t == 1:\n",
    "            Path(f\"results/emb_sim/correct_dif/{xtrans}\").mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(f\"{Path.home()}/.cache/panda/audio_slices/{yn.replace('.pt', '.wav')}\", f\"results/emb_sim/correct_dif/{xtrans}/{ix}_{jx}_{yn.replace('.pt', '.wav')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5005\n",
      "4979\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "print(pos_n)\n",
    "print(neg_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.0\n",
      "76.0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "print(f\"{round(pos_hits/pos_n, 2)*100}\")\n",
    "print(f\"{round(neg_hits/neg_n, 2)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "312it [00:00, 2232.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green green tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "for ix, i in tqdm(enumerate(range(32, len(x1), 32))):\n",
    "    x, y, label = x1[i-32:i], x2[i-32:i], dists[i-32:i]\n",
    "    transx = [Path(j).name.split('_')[0] for j in x]\n",
    "    transy = [Path(j).name.split('_')[0] for j in y]\n",
    "    for jx, jy, l in zip(transx, transy, label):\n",
    "        if (jx != jy) and l == 0:\n",
    "            print(jx, jy, l)\n",
    "        if (jx == jy) and l == 1:\n",
    "            print(jx, jy, l)\n",
    "\n",
    "print(jx, jy, l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
