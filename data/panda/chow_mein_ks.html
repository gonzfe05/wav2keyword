<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>wav2keyword â€“ chow_mein_ks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">wav2keyword</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gonzfe05/wav2keyword"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">(Untitled)</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">wav2keyword</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../core.html" class="sidebar-item-text sidebar-link">wav2vec</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../datasets_tools.html" class="sidebar-item-text sidebar-link">Datasets pipeline</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../preprocesses.html" class="sidebar-item-text sidebar-link">preprocesses</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../training.html" class="sidebar-item-text sidebar-link">training</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../05_one_vs_rest.html" class="sidebar-item-text sidebar-link">Wav2vec2 one vs rest classification</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../06_embeddings_distance.html" class="sidebar-item-text sidebar-link">Wav2vec2 embeddings distance</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../07_audio_processor.html" class="sidebar-item-text sidebar-link">07_audio_processor.html</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#add-label" id="toc-add-label" class="nav-link active" data-scroll-target="#add-label">Add label</a></li>
  <li><a href="#chow-mein" id="toc-chow-mein" class="nav-link" data-scroll-target="#chow-mein">Chow mein</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/gonzfe05/wav2keyword/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="add-label" class="level3">
<h3 class="anchored" data-anchor-id="add-label">Add label</h3>
<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset, Features, Value, Audio, ClassLabel</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>feats <span class="op">=</span> Features({<span class="st">"path"</span>: Value(<span class="st">"string"</span>),</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"audio"</span>: Audio(sampling_rate<span class="op">=</span><span class="dv">16_000</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"label"</span>: ClassLabel(names<span class="op">=</span>[<span class="st">"not found"</span>,<span class="st">"found"</span>])}</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>                  )</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _generate_examples(example, tag):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        example[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> example[<span class="st">'label'</span>] <span class="kw">in</span> tag <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        example[<span class="st">'audio'</span>] <span class="op">=</span> example[<span class="st">'path'</span>]</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> example</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'tags_data.json'</span>, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> json.load(f)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>data_files <span class="op">=</span> {<span class="st">'train'</span>: <span class="st">'dataset/slices_train.csv'</span>, <span class="st">'test'</span>: <span class="st">'dataset/slices_test.csv'</span>, <span class="st">'val'</span>: <span class="st">'dataset/slices_val.csv'</span>}</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"csv"</span>, data_files<span class="op">=</span>data_files)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.remove_columns(column_names<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>, <span class="st">'split'</span>])</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>tags_pool <span class="op">=</span> [k <span class="cf">for</span> k, v <span class="kw">in</span> data.items() <span class="cf">if</span> <span class="st">'chow mein'</span> <span class="kw">in</span> v[<span class="st">'tags'</span>]]</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.<span class="bu">map</span>(_generate_examples, fn_kwargs<span class="op">=</span>{<span class="st">'tag'</span>: tags_pool}, features<span class="op">=</span>feats)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.rename_column(<span class="st">'path'</span>, <span class="st">'file'</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>id2label <span class="op">=</span> {<span class="dv">0</span>: <span class="st">'not found'</span>, <span class="dv">1</span>: <span class="st">'found'</span>}</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>label2id <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> id2label.items()}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Using custom data configuration default-c58ed15a5d5a3dac
Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-c58ed15a5d5a3dac/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"34f328885d314a9da1f1d57c8d1063ac","version_major":2,"version_minor":0}]
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"5eba4228f00941458828f5ebbcbfa86e","version_major":2,"version_minor":0}]
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"f84ec06c2e1c4924baacfa7bb28b1467","version_major":2,"version_minor":0}]
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"0ef17836148a4809b181cd6fb40135b9","version_major":2,"version_minor":0}]
</script>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">'train'</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'file': '/home/jovyan/.cache/panda/audio_slices/water_0_1655689126-SIP-A90CCE12F2CF-000041b2-chunk3.wav',
 'audio': {'path': '/home/jovyan/.cache/panda/audio_slices/water_0_1655689126-SIP-A90CCE12F2CF-000041b2-chunk3.wav',
  'array': array([ 6.1035156e-05,  3.3569336e-04, -4.2724609e-04, ...,
         -4.8522949e-03,  1.3031006e-02,  2.9037476e-02], dtype=float32),
  'sampling_rate': 16000},
 'label': 0}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">'train'</span>].to_pandas().label.value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>0    35787
1     1206
Name: label, dtype: int64</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _filter_by_duration(example, duration):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(example[<span class="st">'audio'</span>][<span class="st">'array'</span>]) <span class="op">&lt;</span> duration <span class="op">*</span> example[<span class="st">'audio'</span>][<span class="st">'sampling_rate'</span>]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.<span class="bu">filter</span>(_filter_by_duration, fn_kwargs<span class="op">=</span>{<span class="st">'duration'</span>: <span class="dv">1</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"b9723a7e77bb41d7b4d1d40ead05d8a2","version_major":2,"version_minor":0}]
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"d98ed39fffcd4f91988a544993518d12","version_major":2,"version_minor":0}]
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"8f45fc7b1682415aa8a219fc34210832","version_major":2,"version_minor":0}]
</script>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>class_counts <span class="op">=</span> dataset[<span class="st">'train'</span>].to_pandas().label.value_counts()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>weight_positive_class <span class="op">=</span> class_counts.iloc[<span class="dv">0</span>]<span class="op">/</span>class_counts.iloc[<span class="dv">1</span>]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(weight_positive_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>30.22027972027972</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoFeatureExtractor</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForAudioClassification, TrainingArguments, Trainer</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset, load_metric</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>model_checkpoint <span class="op">=</span> <span class="st">"facebook/wav2vec2-base"</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>max_duration <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>feature_extractor <span class="op">=</span> AutoFeatureExtractor.from_pretrained(model_checkpoint)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_function(examples):</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    audio_arrays <span class="op">=</span> [x[<span class="st">"array"</span>] <span class="cf">for</span> x <span class="kw">in</span> examples[<span class="st">"audio"</span>]]</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> feature_extractor(</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        audio_arrays, </span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        sampling_rate<span class="op">=</span>feature_extractor.sampling_rate, </span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="bu">int</span>(feature_extractor.sampling_rate <span class="op">*</span> max_duration), </span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> inputs</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>encoded_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(preprocess_function, remove_columns<span class="op">=</span>[<span class="st">"audio"</span>, <span class="st">"file"</span>], batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>num_labels <span class="op">=</span> <span class="bu">len</span>(id2label)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForAudioClassification.from_pretrained(</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    model_checkpoint, </span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span>num_labels,</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    label2id<span class="op">=</span>label2id,</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    id2label<span class="op">=</span>id2label,</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> model_checkpoint.split(<span class="st">"/"</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> TrainingArguments(</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">-finetuned-ks"</span>,</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy <span class="op">=</span> <span class="st">"epoch"</span>,</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    save_strategy <span class="op">=</span> <span class="st">"epoch"</span>,</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">3e-5</span>,</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span>batch_size,</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span>batch_size,</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    warmup_ratio<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>    metric_for_best_model<span class="op">=</span><span class="st">"accuracy"</span>,</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>    push_to_hub<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>loading feature extractor configuration file https://huggingface.co/facebook/wav2vec2-base/resolve/main/preprocessor_config.json from cache at /home/jovyan/.cache/huggingface/transformers/d4583dd9e59eb6295f8fe8b18833ae54d963a122d69aa1df7ecce6caafe18c8f.bc3155ca0bae3a39fc37fc6d64829c6a765f46480894658bb21c08db6155358d
loading configuration file https://huggingface.co/facebook/wav2vec2-base/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/c7746642f045322fd01afa31271dd490e677ea11999e68660a92619ec7c892b4.ce1f96bfaf3d7475cb8187b9668c7f19437ade45fb9ceb78d2b06a2cec198015
/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:368: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base",
  "activation_dropout": 0.0,
  "adapter_kernel_size": 3,
  "adapter_stride": 2,
  "add_adapter": false,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForPreTraining"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "classifier_proj_size": 256,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "sum",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.0,
  "freeze_feat_extract_train": true,
  "gradient_checkpointing": true,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.0,
  "mask_channel_length": 10,
  "mask_channel_min_space": 1,
  "mask_channel_other": 0.0,
  "mask_channel_prob": 0.0,
  "mask_channel_selection": "static",
  "mask_feature_length": 10,
  "mask_feature_min_masks": 0,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_min_masks": 2,
  "mask_time_min_space": 1,
  "mask_time_other": 0.0,
  "mask_time_prob": 0.05,
  "mask_time_selection": "static",
  "model_type": "wav2vec2",
  "no_mask_channel_overlap": false,
  "no_mask_time_overlap": false,
  "num_adapter_layers": 3,
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "output_hidden_size": 768,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "tdnn_dilation": [
    1,
    2,
    3,
    1,
    1
  ],
  "tdnn_dim": [
    512,
    512,
    512,
    512,
    1500
  ],
  "tdnn_kernel": [
    5,
    3,
    3,
    1,
    1
  ],
  "transformers_version": "4.21.2",
  "use_weighted_layer_sum": false,
  "vocab_size": 32,
  "xvector_output_dim": 512
}

Feature extractor Wav2Vec2FeatureExtractor {
  "do_normalize": true,
  "feature_extractor_type": "Wav2Vec2FeatureExtractor",
  "feature_size": 1,
  "padding_side": "right",
  "padding_value": 0.0,
  "return_attention_mask": false,
  "sampling_rate": 16000
}
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"04c1ae0720c2420ea677388d576048cd","version_major":2,"version_minor":0}]
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  tensor = as_tensor(value)</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"3a81a7a5f96240ba9a9a18cd907b43e0","version_major":2,"version_minor":0}]
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
[{"model_id":"04ec551ce1504cd4843f0b6a2591ec6e","version_major":2,"version_minor":0}]
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>loading configuration file https://huggingface.co/facebook/wav2vec2-base/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/c7746642f045322fd01afa31271dd490e677ea11999e68660a92619ec7c892b4.ce1f96bfaf3d7475cb8187b9668c7f19437ade45fb9ceb78d2b06a2cec198015
Model config Wav2Vec2Config {
  "_name_or_path": "facebook/wav2vec2-base",
  "activation_dropout": 0.0,
  "adapter_kernel_size": 3,
  "adapter_stride": 2,
  "add_adapter": false,
  "apply_spec_augment": true,
  "architectures": [
    "Wav2Vec2ForPreTraining"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 1,
  "classifier_proj_size": 256,
  "codevector_dim": 256,
  "contrastive_logits_temperature": 0.1,
  "conv_bias": false,
  "conv_dim": [
    512,
    512,
    512,
    512,
    512,
    512,
    512
  ],
  "conv_kernel": [
    10,
    3,
    3,
    3,
    3,
    2,
    2
  ],
  "conv_stride": [
    5,
    2,
    2,
    2,
    2,
    2,
    2
  ],
  "ctc_loss_reduction": "sum",
  "ctc_zero_infinity": false,
  "diversity_loss_weight": 0.1,
  "do_stable_layer_norm": false,
  "eos_token_id": 2,
  "feat_extract_activation": "gelu",
  "feat_extract_norm": "group",
  "feat_proj_dropout": 0.1,
  "feat_quantizer_dropout": 0.0,
  "final_dropout": 0.0,
  "freeze_feat_extract_train": true,
  "gradient_checkpointing": true,
  "hidden_act": "gelu",
  "hidden_dropout": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "not found",
    "1": "found"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "found": 1,
    "not found": 0
  },
  "layer_norm_eps": 1e-05,
  "layerdrop": 0.0,
  "mask_channel_length": 10,
  "mask_channel_min_space": 1,
  "mask_channel_other": 0.0,
  "mask_channel_prob": 0.0,
  "mask_channel_selection": "static",
  "mask_feature_length": 10,
  "mask_feature_min_masks": 0,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_min_masks": 2,
  "mask_time_min_space": 1,
  "mask_time_other": 0.0,
  "mask_time_prob": 0.05,
  "mask_time_selection": "static",
  "model_type": "wav2vec2",
  "no_mask_channel_overlap": false,
  "no_mask_time_overlap": false,
  "num_adapter_layers": 3,
  "num_attention_heads": 12,
  "num_codevector_groups": 2,
  "num_codevectors_per_group": 320,
  "num_conv_pos_embedding_groups": 16,
  "num_conv_pos_embeddings": 128,
  "num_feat_extract_layers": 7,
  "num_hidden_layers": 12,
  "num_negatives": 100,
  "output_hidden_size": 768,
  "pad_token_id": 0,
  "proj_codevector_dim": 256,
  "tdnn_dilation": [
    1,
    2,
    3,
    1,
    1
  ],
  "tdnn_dim": [
    512,
    512,
    512,
    512,
    1500
  ],
  "tdnn_kernel": [
    5,
    3,
    3,
    1,
    1
  ],
  "transformers_version": "4.21.2",
  "use_weighted_layer_sum": false,
  "vocab_size": 32,
  "xvector_output_dim": 512
}

loading weights file https://huggingface.co/facebook/wav2vec2-base/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/ef45231897ce572a660ebc5a63d3702f1a6041c4c5fb78cbec330708531939b3.fcae05302a685f7904c551c8ea571e8bc2a2c4a1777ea81ad66e47f7883a650a
Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['project_q.weight', 'project_hid.weight', 'quantizer.codevectors', 'project_hid.bias', 'quantizer.weight_proj.bias', 'project_q.bias', 'quantizer.weight_proj.weight']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'projector.bias', 'classifier.weight', 'projector.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
PyTorch: setting up devices
The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>metric <span class="op">=</span> load_metric(<span class="st">"accuracy"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(eval_pred):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Computes accuracy on a batch of predictions"""</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(eval_pred.predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> metric.compute(predictions<span class="op">=</span>predictions, references<span class="op">=</span>eval_pred.label_ids)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CustomTrainer(Trainer):</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_loss(<span class="va">self</span>, model, inputs, return_outputs<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> inputs.get(<span class="st">"labels"</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># forward pass</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> outputs.get(<span class="st">"logits"</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute custom loss (2 labels with different weights)</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        loss_fct <span class="op">=</span> nn.CrossEntropyLoss(weight<span class="op">=</span>torch.tensor([<span class="fl">1.0</span>, <span class="fl">1.35</span>]).cuda())</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        logits_view <span class="op">=</span> logits.view(<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.model.config.num_labels)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fct(logits_view, labels.view(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (loss, outputs) <span class="cf">if</span> return_outputs <span class="cf">else</span> loss</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> CustomTrainer(</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    model,</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    args,</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>encoded_dataset[<span class="st">"train"</span>],</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>encoded_dataset[<span class="st">"val"</span>],</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>feature_extractor,</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 35708
  Num Epochs = 15
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed &amp; accumulation) = 128
  Gradient Accumulation steps = 4
  Total optimization steps = 4185</code></pre>
</div>
<div class="cell-output cell-output-display">


    <div>
      
      <progress value="4185" max="4185" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [4185/4185 2:23:46, Epoch 15/15]
    </div>
    <table class="dataframe table table-sm table-striped">
  <thead>
 <tr>
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0.411200</td>
      <td>0.306926</td>
      <td>0.882207</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.283400</td>
      <td>0.227008</td>
      <td>0.904730</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.242800</td>
      <td>0.193498</td>
      <td>0.914414</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.221000</td>
      <td>0.166870</td>
      <td>0.923874</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.227800</td>
      <td>0.159021</td>
      <td>0.926802</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.197600</td>
      <td>0.158407</td>
      <td>0.931081</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.207700</td>
      <td>0.141965</td>
      <td>0.934685</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.181700</td>
      <td>0.148205</td>
      <td>0.929054</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.172800</td>
      <td>0.138138</td>
      <td>0.936036</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.186800</td>
      <td>0.141322</td>
      <td>0.933333</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.180400</td>
      <td>0.133537</td>
      <td>0.935811</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.170000</td>
      <td>0.132791</td>
      <td>0.934910</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.153300</td>
      <td>0.133605</td>
      <td>0.933784</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.126600</td>
      <td>0.132347</td>
      <td>0.935811</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.144800</td>
      <td>0.129441</td>
      <td>0.936486</td>
    </tr>
  </tbody>
</table><p>
</p></div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-279
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-279/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-279/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-279/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-558
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-558/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-558/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-558/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-837
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-837/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-837/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-837/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-1116
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-1116/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-1116/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-1116/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-1395
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-1395/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-1395/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-1395/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-1674
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-1674/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-1674/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-1674/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-1953
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-1953/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-1953/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-1953/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-2232
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-2232/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-2232/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-2232/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-2511
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-2511/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-2511/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-2511/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-2790
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-2790/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-2790/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-2790/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-3069
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-3069/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-3069/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-3069/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-3348
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-3348/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-3348/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-3348/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-3627
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-3627/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-3627/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-3627/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-3906
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-3906/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-3906/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-3906/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 4440
  Batch size = 32
Saving model checkpoint to wav2vec2-base-finetuned-ks/checkpoint-4185
Configuration saved in wav2vec2-base-finetuned-ks/checkpoint-4185/config.json
Model weights saved in wav2vec2-base-finetuned-ks/checkpoint-4185/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/checkpoint-4185/preprocessor_config.json


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from wav2vec2-base-finetuned-ks/checkpoint-4185 (score: 0.9364864864864865).</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>TrainOutput(global_step=4185, training_loss=0.21789302935594584, metrics={'train_runtime': 8628.3807, 'train_samples_per_second': 62.077, 'train_steps_per_second': 0.485, 'total_flos': 4.3021878417689375e+18, 'train_loss': 0.21789302935594584, 'epoch': 15.0})</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>dataset.cleanup_cache_files()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'train': 5, 'test': 1, 'val': 0, 'validation': 0}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>trainer.save_model(<span class="ss">f"wav2vec2-base-finetuned-ks/best_checkpoint"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Saving model checkpoint to wav2vec2-base-finetuned-ks/best_checkpoint
Configuration saved in wav2vec2-base-finetuned-ks/best_checkpoint/config.json
Model weights saved in wav2vec2-base-finetuned-ks/best_checkpoint/pytorch_model.bin
Feature extractor saved in wav2vec2-base-finetuned-ks/best_checkpoint/preprocessor_config.json</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> encoded_dataset[<span class="st">'test'</span>]</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> trainer.predict(test_dataset <span class="op">=</span> inputs)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running Prediction *****
  Num examples = 4479
  Batch size = 32</code></pre>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<pre><code>PredictionOutput(predictions=array([[ 1.2470611, -1.2712642],
       [ 3.5061896, -3.6580167],
       [ 3.2142575, -3.3506398],
       ...,
       [ 3.4247284, -3.5656137],
       [ 3.067631 , -3.2232652],
       [ 3.5443592, -3.709301 ]], dtype=float32), label_ids=array([0, 0, 0, ..., 0, 0, 0]), metrics={'test_loss': 0.1558578908443451, 'test_accuracy': 0.9278856887698147, 'test_runtime': 28.6291, 'test_samples_per_second': 156.449, 'test_steps_per_second': 4.89})</code></pre>
</div>
</div>
</section>
<section id="chow-mein" class="level2">
<h2 class="anchored" data-anchor-id="chow-mein">Chow mein</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>predicted_labels <span class="op">=</span> np.argmax(result.predictions, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>positive_hits <span class="op">=</span> [p<span class="op">==</span>t <span class="cf">for</span> p, t <span class="kw">in</span> <span class="bu">zip</span>(predicted_labels, inputs[<span class="st">'label'</span>]) <span class="cf">if</span> t <span class="op">==</span> <span class="dv">1</span>]</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>correct_positive <span class="op">=</span> <span class="bu">sum</span>(positive_hits)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>correct_negative <span class="op">=</span> <span class="bu">sum</span>([p<span class="op">==</span>t <span class="cf">for</span> p, t <span class="kw">in</span> <span class="bu">zip</span>(predicted_labels, inputs[<span class="st">'label'</span>]) <span class="cf">if</span> t <span class="op">==</span> <span class="dv">0</span>])</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>n_positive <span class="op">=</span> <span class="bu">sum</span>(inputs[<span class="st">'label'</span>])</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>n_negative <span class="op">=</span> <span class="bu">len</span>(inputs[<span class="st">'label'</span>]) <span class="op">-</span> n_positive</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Overall accuracy: </span><span class="sc">{</span>(correct_positive <span class="op">+</span> correct_negative) <span class="op">/</span> (n_positive <span class="op">+</span> n_negative)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive accutacy: </span><span class="sc">{</span>correct_positive <span class="op">/</span> n_positive<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative accuracy: </span><span class="sc">{</span>correct_negative <span class="op">/</span> n_negative<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overall accuracy: 0.9752176825184193
Positive accutacy: 0.7633587786259542
Negative accuracy: 0.9816007359705612</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>positive_hits_files <span class="op">=</span> [f <span class="cf">for</span> p, t, f <span class="kw">in</span> <span class="bu">zip</span>(predicted_labels, dataset[<span class="st">'test'</span>][<span class="st">'label'</span>], dataset[<span class="st">'test'</span>][<span class="st">'file'</span>]) <span class="cf">if</span> t <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> p<span class="op">==</span>t]</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> f <span class="kw">in</span> positive_hits_files:</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    shutil.copy(f, <span class="ss">f"found/</span><span class="sc">{</span>Path(f)<span class="sc">.</span>name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>positive_miss_files <span class="op">=</span> [f <span class="cf">for</span> p, t, f <span class="kw">in</span> <span class="bu">zip</span>(predicted_labels, dataset[<span class="st">'test'</span>][<span class="st">'label'</span>], dataset[<span class="st">'test'</span>][<span class="st">'file'</span>]) <span class="cf">if</span> t <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> p<span class="op">!=</span>t]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> f <span class="kw">in</span> positive_miss_files:</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    shutil.copy(f, <span class="ss">f"not found/</span><span class="sc">{</span>Path(f)<span class="sc">.</span>name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>